#!/usr/bin/env python3
"""
é«˜çº§æ•°æ®è´¨é‡è¯Šæ–­å·¥å…·

åŠŸèƒ½ï¼š
1. æ£€æŸ¥ç©ºå€¼ã€æ— ç©·å¤§ã€å¼‚å¸¸å€¼
2. æ£€æŸ¥è½¨è¿¹è¿ç»­æ€§ï¼ˆé€Ÿåº¦/åŠ é€Ÿåº¦çªå˜ï¼‰
3. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ˆå›¾åƒã€å…ƒæ•°æ®ï¼‰
4. è¯„åˆ†ç³»ç»Ÿï¼Œç­›é€‰ä¼˜è´¨è½¨è¿¹
5. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šå’Œå¯è§†åŒ–
"""

import os
import sys
import numpy as np
import h5py
from glob import glob
import argparse
import json
from collections import defaultdict


class EpisodeQualityChecker:
    """å•ä¸ª Episode çš„è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self, ep_path, dt=0.01):
        self.ep_path = ep_path
        self.ep_name = os.path.basename(ep_path)
        self.dt = dt  # æ§åˆ¶é¢‘ç‡æ—¶é—´æ­¥
        
        self.issues = []
        self.warnings = []
        self.stats = {}
        self.score = 100  # åˆå§‹æ»¡åˆ†
        
    def check(self):
        """æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥"""
        hdf5_path = os.path.join(self.ep_path, "data.hdf5")
        
        if not os.path.exists(hdf5_path):
            self.issues.append("HDF5 æ–‡ä»¶ä¸å­˜åœ¨")
            self.score = 0
            return self.get_result()
        
        try:
            with h5py.File(hdf5_path, 'r') as f:
                # 1. åŸºç¡€æ£€æŸ¥
                self._check_data_structure(f)
                
                # 2. åŠ è½½æ•°æ®
                joint_pos, gripper_width, timestamps = self._load_data(f)
                
                if joint_pos is None:
                    return self.get_result()
                
                # 2.5 è®¡ç®—å®é™…æ—¶é—´æ­¥ï¼ˆå¦‚æœæœ‰ timestampï¼‰
                actual_dt = self._compute_actual_dt(timestamps, joint_pos.shape[0])
                if actual_dt is not None:
                    self.dt = actual_dt
                    self.stats['actual_dt'] = float(actual_dt)
                    self.stats['actual_frequency'] = float(1.0 / actual_dt)
                
                # 3. æ•°å€¼æ£€æŸ¥
                self._check_values(joint_pos, gripper_width)
                
                # 4. è½¨è¿¹è¿ç»­æ€§æ£€æŸ¥
                self._check_trajectory_continuity(joint_pos, gripper_width)
                
                # 5. ç»Ÿè®¡ä¿¡æ¯
                self._compute_statistics(joint_pos, gripper_width)
                
                # 6. å›¾åƒæ•°æ®æ£€æŸ¥
                self._check_images(f)
                
                # 7. å…ƒæ•°æ®æ£€æŸ¥
                self._check_metadata()
                
        except Exception as e:
            self.issues.append(f"è¯»å–å¤±è´¥: {e}")
            self.score = 0
        
        return self.get_result()
    
    def _check_data_structure(self, f):
        """æ£€æŸ¥æ•°æ®ç»“æ„å®Œæ•´æ€§"""
        required_fields = [
            'state/joint/position',
            'state/joint/gripper_width',
            'action/joint/position',
            'action/joint/gripper_width',
        ]
        
        missing_fields = []
        for field in required_fields:
            if field not in f:
                missing_fields.append(field)
        
        if missing_fields:
            self.issues.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}")
            self.score -= 50
    
    def _compute_actual_dt(self, timestamps, n_steps):
        """ä» timestamp è®¡ç®—å®é™…çš„æ—¶é—´æ­¥"""
        if timestamps is None or len(timestamps) < 2:
            return None
        
        # ç¡®ä¿ timestamps å’Œ joint_pos é•¿åº¦ä¸€è‡´
        if len(timestamps) != n_steps:
            self.warnings.append(f"Timestamp æ•°é‡ ({len(timestamps)}) ä¸æ­¥æ•° ({n_steps}) ä¸åŒ¹é…")
            return None
        
        # è®¡ç®—ç›¸é‚»å¸§çš„æ—¶é—´å·®
        dt_array = np.diff(timestamps)
        
        # è¿‡æ»¤æ‰å¼‚å¸¸å€¼ï¼ˆæ¯”å¦‚æš‚åœé‡‡é›†æ—¶çš„å¤§é—´éš”ï¼‰
        valid_dt = dt_array[dt_array < 1.0]  # å‡è®¾é‡‡é›†é¢‘ç‡ > 1Hz
        
        if len(valid_dt) == 0:
            return None
        
        # ä½¿ç”¨ä¸­ä½æ•°ä½œä¸ºå®é™… dtï¼ˆæ¯”å‡å€¼æ›´é²æ£’ï¼‰
        actual_dt = np.median(valid_dt)
        
        return actual_dt
    
    def _load_data(self, f):
        """åŠ è½½æ•°æ®"""
        try:
            joint_pos = f['state/joint/position'][:]
            gripper_width = f['state/joint/gripper_width'][:]
            
            # å°è¯•åŠ è½½ timestampï¼ˆå¦‚æœæœ‰ï¼‰
            timestamps = None
            if 'observation/rgb_timestamp' in f:
                timestamps = f['observation/rgb_timestamp'][:]
            
            return joint_pos, gripper_width, timestamps
        except Exception as e:
            self.issues.append(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None, None, None
    
    def _check_values(self, joint_pos, gripper_width):
        """æ£€æŸ¥æ•°å€¼èŒƒå›´å’Œæœ‰æ•ˆæ€§"""
        
        # æ£€æŸ¥ NaN
        nan_joints = np.any(np.isnan(joint_pos))
        nan_gripper = np.any(np.isnan(gripper_width))
        
        if nan_joints:
            self.issues.append("å…³èŠ‚ä½ç½®åŒ…å« NaN")
            self.score -= 30
        
        if nan_gripper:
            self.issues.append("å¤¹çˆªå®½åº¦åŒ…å« NaN")
            self.score -= 20
        
        # æ£€æŸ¥ Inf
        inf_joints = np.any(np.isinf(joint_pos))
        inf_gripper = np.any(np.isinf(gripper_width))
        
        if inf_joints:
            self.issues.append("å…³èŠ‚ä½ç½®åŒ…å« Inf")
            self.score -= 30
        
        if inf_gripper:
            self.issues.append("å¤¹çˆªå®½åº¦åŒ…å« Inf")
            self.score -= 20
        
        # æ£€æŸ¥å…³èŠ‚è§’åº¦èŒƒå›´ï¼ˆæ­£å¸¸åº”è¯¥åœ¨ [-2Ï€, 2Ï€]ï¼‰
        max_joint = np.max(np.abs(joint_pos))
        if max_joint > 10:
            self.issues.append(f"å…³èŠ‚è§’åº¦å¼‚å¸¸å¤§: {max_joint:.2e}")
            self.score -= 40
        elif max_joint > 6.5:  # ç•¥å¤§äº 2Ï€
            self.warnings.append(f"å…³èŠ‚è§’åº¦åå¤§: {max_joint:.2f}")
            self.score -= 10
        
        # æ£€æŸ¥å¤¹çˆªèŒƒå›´ï¼ˆåº”è¯¥åœ¨ [0, 0.088]ï¼‰
        min_gripper = np.min(gripper_width)
        max_gripper = np.max(gripper_width)
        
        if min_gripper < -0.01 or max_gripper > 0.1:
            self.issues.append(f"å¤¹çˆªå®½åº¦è¶…å‡ºèŒƒå›´: [{min_gripper:.4f}, {max_gripper:.4f}]")
            self.score -= 25
        elif min_gripper < 0 or max_gripper > 0.09:
            self.warnings.append(f"å¤¹çˆªå®½åº¦æ¥è¿‘è¾¹ç•Œ: [{min_gripper:.4f}, {max_gripper:.4f}]")
            self.score -= 5
    
    def _check_trajectory_continuity(self, joint_pos, gripper_width):
        """æ£€æŸ¥è½¨è¿¹è¿ç»­æ€§ï¼ˆæ£€æµ‹çªå˜ï¼‰"""
        
        # è®¡ç®—é€Ÿåº¦ï¼ˆä¸€é˜¶å·®åˆ†ï¼‰
        joint_vel = np.diff(joint_pos, axis=0) / self.dt
        gripper_vel = np.diff(gripper_width) / self.dt
        
        # è®¡ç®—åŠ é€Ÿåº¦ï¼ˆäºŒé˜¶å·®åˆ†ï¼‰
        joint_acc = np.diff(joint_vel, axis=0) / self.dt
        gripper_acc = np.diff(gripper_vel) / self.dt
        
        # æ£€æŸ¥é€Ÿåº¦çªå˜ï¼ˆå…³èŠ‚é€Ÿåº¦é€šå¸¸ < 5 rad/sï¼‰
        max_joint_vel = np.max(np.abs(joint_vel))
        if max_joint_vel > 10:
            self.issues.append(f"å…³èŠ‚é€Ÿåº¦å¼‚å¸¸å¤§: {max_joint_vel:.2f} rad/s")
            self.score -= 20
        elif max_joint_vel > 6:
            self.warnings.append(f"å…³èŠ‚é€Ÿåº¦åå¤§: {max_joint_vel:.2f} rad/s")
            self.score -= 5
        
        # æ£€æŸ¥åŠ é€Ÿåº¦çªå˜ï¼ˆå…³èŠ‚åŠ é€Ÿåº¦é€šå¸¸ < 50 rad/sÂ²ï¼‰
        max_joint_acc = np.max(np.abs(joint_acc))
        if max_joint_acc > 100:
            self.issues.append(f"å…³èŠ‚åŠ é€Ÿåº¦å¼‚å¸¸å¤§: {max_joint_acc:.2f} rad/sÂ²")
            self.score -= 15
        elif max_joint_acc > 60:
            self.warnings.append(f"å…³èŠ‚åŠ é€Ÿåº¦åå¤§: {max_joint_acc:.2f} rad/sÂ²")
            self.score -= 3
        
        # æ£€æŸ¥å•æ­¥çªå˜ï¼ˆç›¸é‚»å¸§å˜åŒ–è¿‡å¤§ï¼‰
        max_single_step = np.max(np.abs(np.diff(joint_pos, axis=0)), axis=0)
        sudden_jump_threshold = 0.5  # å•æ­¥å˜åŒ–è¶…è¿‡ 0.5 rad è®¤ä¸ºæ˜¯çªå˜
        
        sudden_jumps = max_single_step > sudden_jump_threshold
        if np.any(sudden_jumps):
            jump_joints = np.where(sudden_jumps)[0]
            self.warnings.append(f"å…³èŠ‚ {jump_joints} å­˜åœ¨çªå˜ (Î” > {sudden_jump_threshold})")
            self.score -= 10
        
        # æ£€æŸ¥å¤¹çˆªé€Ÿåº¦
        max_gripper_vel = np.max(np.abs(gripper_vel))
        if max_gripper_vel > 0.5:  # å¤¹çˆªé€Ÿåº¦é€šå¸¸ < 0.3 m/s
            self.warnings.append(f"å¤¹çˆªé€Ÿåº¦åå¤§: {max_gripper_vel:.2f} m/s")
            self.score -= 3
        
        # ç»Ÿè®¡
        self.stats['max_joint_velocity'] = float(max_joint_vel)
        self.stats['max_joint_acceleration'] = float(max_joint_acc)
        self.stats['max_gripper_velocity'] = float(max_gripper_vel)
        self.stats['max_single_step_change'] = float(np.max(max_single_step))
    
    def _compute_statistics(self, joint_pos, gripper_width):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        
        self.stats['n_steps'] = int(joint_pos.shape[0])
        self.stats['duration'] = float(joint_pos.shape[0] * self.dt)
        self.stats['dt_used'] = float(self.dt)
        
        self.stats['joint_position'] = {
            'shape': joint_pos.shape,
            'mean': float(np.mean(joint_pos)),
            'std': float(np.std(joint_pos)),
            'min': float(np.min(joint_pos)),
            'max': float(np.max(joint_pos)),
        }
        
        self.stats['gripper_width'] = {
            'mean': float(np.mean(gripper_width)),
            'std': float(np.std(gripper_width)),
            'min': float(np.min(gripper_width)),
            'max': float(np.max(gripper_width)),
        }
        
        # è¿åŠ¨èŒƒå›´ï¼ˆå…³èŠ‚æ´»åŠ¨åº¦ï¼‰
        joint_range = np.max(joint_pos, axis=0) - np.min(joint_pos, axis=0)
        self.stats['joint_range'] = [float(x) for x in joint_range]
        self.stats['avg_joint_range'] = float(np.mean(joint_range))
        
        # å¦‚æœè¿åŠ¨èŒƒå›´å¤ªå°ï¼Œå¯èƒ½æ˜¯é™æ­¢æ•°æ®
        if np.mean(joint_range) < 0.1:
            self.warnings.append(f"å…³èŠ‚è¿åŠ¨èŒƒå›´å¾ˆå°: {np.mean(joint_range):.3f} rad")
            self.score -= 5
    
    def _check_images(self, f):
        """æ£€æŸ¥å›¾åƒæ•°æ®"""
        if 'observation/rgb' not in f:
            self.warnings.append("ç¼ºå°‘å›¾åƒæ•°æ®")
            self.score -= 5
            return
        
        try:
            rgb_group = f['observation/rgb']
            n_frames = len(rgb_group.keys())
            
            if n_frames == 0:
                self.issues.append("å›¾åƒæ•°æ®ä¸ºç©º")
                self.score -= 20
            else:
                # æ£€æŸ¥ç¬¬ä¸€å¸§
                first_frame = rgb_group['0'][:]
                
                # æ£€æŸ¥å›¾åƒæ˜¯å¦å…¨é»‘æˆ–å…¨ç™½
                if np.all(first_frame == 0):
                    self.warnings.append("é¦–å¸§å›¾åƒå…¨é»‘")
                    self.score -= 5
                elif np.all(first_frame == 255):
                    self.warnings.append("é¦–å¸§å›¾åƒå…¨ç™½")
                    self.score -= 5
                
                self.stats['n_frames'] = n_frames
                self.stats['image_shape'] = first_frame.shape
                
                # æ£€æŸ¥å¸§æ•°å’Œæ­¥æ•°æ˜¯å¦åŒ¹é…
                expected_frames = self.stats.get('n_steps', 0)
                if n_frames != expected_frames and expected_frames > 0:
                    self.warnings.append(f"å›¾åƒå¸§æ•° ({n_frames}) ä¸æ•°æ®æ­¥æ•° ({expected_frames}) ä¸åŒ¹é…")
                    self.score -= 10
                    
        except Exception as e:
            self.warnings.append(f"å›¾åƒæ£€æŸ¥å¤±è´¥: {e}")
            self.score -= 5
    
    def _check_metadata(self):
        """æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶"""
        metadata_path = os.path.join(self.ep_path, "metadata.json")
        
        if not os.path.exists(metadata_path):
            self.warnings.append("ç¼ºå°‘ metadata.json")
            self.score -= 3
        else:
            try:
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
                    self.stats['metadata'] = metadata
            except Exception as e:
                self.warnings.append(f"metadata è¯»å–å¤±è´¥: {e}")
                self.score -= 3
    
    def get_result(self):
        """è¿”å›æ£€æŸ¥ç»“æœ"""
        # ç¡®ä¿åˆ†æ•°åœ¨ 0-100 èŒƒå›´å†…
        self.score = max(0, min(100, self.score))
        
        # åˆ¤å®šè´¨é‡ç­‰çº§
        if self.score >= 90:
            quality = "ä¼˜ç§€"
        elif self.score >= 75:
            quality = "è‰¯å¥½"
        elif self.score >= 60:
            quality = "ä¸€èˆ¬"
        elif self.score >= 40:
            quality = "è¾ƒå·®"
        else:
            quality = "åŠ£è´¨"
        
        return {
            'ep_name': self.ep_name,
            'ep_path': self.ep_path,
            'score': self.score,
            'quality': quality,
            'issues': self.issues,
            'warnings': self.warnings,
            'stats': self.stats,
            'is_usable': self.score >= 60,  # 60åˆ†ä»¥ä¸Šè®¤ä¸ºå¯ç”¨
        }


def diagnose_dataset(task_dir, dt=0.01, min_score=60, save_report=True):
    """è¯Šæ–­æ•´ä¸ªæ•°æ®é›†"""
    
    episode_dirs = sorted(glob(os.path.join(task_dir, "episode_*")))
    
    if not episode_dirs:
        print(f"[ERROR] åœ¨ {task_dir} ä¸­æ²¡æœ‰æ‰¾åˆ° episode ç›®å½•")
        return None
    
    print("=" * 80)
    print("ğŸ” é«˜çº§æ•°æ®è´¨é‡è¯Šæ–­")
    print("=" * 80)
    print(f"æ•°æ®ç›®å½•: {task_dir}")
    print(f"Episode æ•°é‡: {len(episode_dirs)}")
    print(f"æœ€ä½å¯ç”¨åˆ†æ•°: {min_score}")
    print("=" * 80)
    print()
    
    results = []
    
    # é€ä¸ªæ£€æŸ¥
    for ep_dir in episode_dirs:
        checker = EpisodeQualityChecker(ep_dir, dt=dt)
        result = checker.check()
        results.append(result)
        
        # å®æ—¶æ˜¾ç¤º
        ep_name = result['ep_name']
        score = result['score']
        quality = result['quality']
        
        if score >= 90:
            icon = "âœ…"
        elif score >= 75:
            icon = "ğŸŸ¢"
        elif score >= 60:
            icon = "ğŸŸ¡"
        elif score >= 40:
            icon = "ğŸŸ "
        else:
            icon = "ğŸ”´"
        
        # æ˜¾ç¤ºå®é™…é¢‘ç‡ï¼ˆå¦‚æœæœ‰ï¼‰
        freq_info = ""
        if 'actual_frequency' in result['stats']:
            actual_freq = result['stats']['actual_frequency']
            freq_info = f" @ {actual_freq:.1f}Hz"
        
        print(f"{icon} {ep_name:15s} | åˆ†æ•°: {score:3d} | è´¨é‡: {quality:4s}{freq_info}", end='')
        
        if result['issues']:
            print(f" | âš ï¸  {len(result['issues'])} ä¸ªä¸¥é‡é—®é¢˜")
        elif result['warnings']:
            print(f" | âš¡ {len(result['warnings'])} ä¸ªè­¦å‘Š")
        else:
            print()
    
    # ç»Ÿè®¡æ±‡æ€»
    print("\n" + "=" * 80)
    print("ğŸ“Š ç»Ÿè®¡æ±‡æ€»")
    print("=" * 80)
    
    scores = [r['score'] for r in results]
    usable = [r for r in results if r['is_usable']]
    excellent = [r for r in results if r['score'] >= 90]
    good = [r for r in results if 75 <= r['score'] < 90]
    fair = [r for r in results if 60 <= r['score'] < 75]
    poor = [r for r in results if 40 <= r['score'] < 60]
    bad = [r for r in results if r['score'] < 40]
    
    print(f"æ€» Episode æ•°: {len(results)}")
    print(f"  âœ… ä¼˜ç§€ (â‰¥90):  {len(excellent):3d} ä¸ª")
    print(f"  ğŸŸ¢ è‰¯å¥½ (75-89): {len(good):3d} ä¸ª")
    print(f"  ğŸŸ¡ ä¸€èˆ¬ (60-74): {len(fair):3d} ä¸ª")
    print(f"  ğŸŸ  è¾ƒå·® (40-59): {len(poor):3d} ä¸ª")
    print(f"  ğŸ”´ åŠ£è´¨ (<40):   {len(bad):3d} ä¸ª")
    print()
    print(f"å¯ç”¨æ•°æ® (â‰¥{min_score}åˆ†): {len(usable)}/{len(results)} ({100*len(usable)/len(results):.1f}%)")
    print(f"å¹³å‡åˆ†æ•°: {np.mean(scores):.1f}")
    print(f"ä¸­ä½åˆ†æ•°: {np.median(scores):.1f}")
    
    # æ˜¾ç¤ºå®é™…é‡‡æ ·é¢‘ç‡ä¿¡æ¯
    actual_freqs = [r['stats'].get('actual_frequency') for r in results if 'actual_frequency' in r['stats']]
    if actual_freqs:
        print(f"\nå®é™…é‡‡æ ·é¢‘ç‡:")
        print(f"  å¹³å‡: {np.mean(actual_freqs):.1f} Hz")
        print(f"  èŒƒå›´: [{np.min(actual_freqs):.1f}, {np.max(actual_freqs):.1f}] Hz")
        if np.mean(actual_freqs) < 50:
            print(f"  âš ï¸  é‡‡æ ·é¢‘ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–é‡‡é›†ä»£ç ")
    
    # ç»Ÿè®¡é—®é¢˜ç±»å‹
    all_issues = []
    all_warnings = []
    for r in results:
        all_issues.extend(r['issues'])
        all_warnings.extend(r['warnings'])
    
    if all_issues:
        print(f"\nâŒ ä¸¥é‡é—®é¢˜æ±‡æ€» ({len(all_issues)} ä¸ª):")
        issue_counts = defaultdict(int)
        for issue in all_issues:
            # æå–é—®é¢˜ç±»å‹ï¼ˆå†’å·å‰çš„éƒ¨åˆ†ï¼‰
            issue_type = issue.split(':')[0] if ':' in issue else issue
            issue_counts[issue_type] += 1
        
        for issue_type, count in sorted(issue_counts.items(), key=lambda x: -x[1]):
            print(f"  - {issue_type}: {count} æ¬¡")
    
    if all_warnings:
        print(f"\nâš¡ è­¦å‘Šæ±‡æ€» ({len(all_warnings)} ä¸ª):")
        warning_counts = defaultdict(int)
        for warning in all_warnings:
            warning_type = warning.split(':')[0] if ':' in warning else warning
            warning_counts[warning_type] += 1
        
        for warning_type, count in sorted(warning_counts.items(), key=lambda x: -x[1])[:10]:
            print(f"  - {warning_type}: {count} æ¬¡")
    
    # æ¨èçš„ episode
    print("\n" + "=" * 80)
    print("ğŸ’¡ æ¨èä½¿ç”¨çš„ Episode")
    print("=" * 80)
    
    if usable:
        print(f"\næ¨èä¿ç•™ä»¥ä¸‹ {len(usable)} ä¸ªé«˜è´¨é‡ episodeï¼š")
        for r in sorted(usable, key=lambda x: -x['score']):
            print(f"  {r['ep_name']:15s} (åˆ†æ•°: {r['score']:3d}, {r['stats'].get('n_steps', 0):4d} æ­¥)")
    else:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è´¨é‡è¶³å¤Ÿå¥½çš„ episodeï¼")
    
    # éœ€è¦åˆ é™¤çš„ episode
    unusable = [r for r in results if not r['is_usable']]
    if unusable:
        print(f"\nå»ºè®®åˆ é™¤ä»¥ä¸‹ {len(unusable)} ä¸ªä½è´¨é‡ episodeï¼š")
        for r in sorted(unusable, key=lambda x: x['score']):
            issues_str = f" ({', '.join(r['issues'][:2])}...)" if r['issues'] else ""
            print(f"  {r['ep_name']:15s} (åˆ†æ•°: {r['score']:3d}){issues_str}")
    
    # ä¿å­˜æŠ¥å‘Š
    if save_report:
        report_path = os.path.join(task_dir, "quality_report.json")
        with open(report_path, 'w') as f:
            json.dump({
                'summary': {
                    'total': len(results),
                    'usable': len(usable),
                    'excellent': len(excellent),
                    'good': len(good),
                    'fair': len(fair),
                    'poor': len(poor),
                    'bad': len(bad),
                    'avg_score': float(np.mean(scores)),
                    'median_score': float(np.median(scores)),
                },
                'episodes': results,
            }, f, indent=2)
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    print("=" * 80)
    
    return results


def generate_clean_command(results, min_score=60):
    """ç”Ÿæˆæ¸…ç†å‘½ä»¤"""
    unusable = [r['ep_name'] for r in results if not r['is_usable']]
    
    if not unusable:
        return None
    
    print("\n" + "=" * 80)
    print("ğŸ§¹ è‡ªåŠ¨æ¸…ç†å‘½ä»¤")
    print("=" * 80)
    print("\nå¤åˆ¶ä»¥ä¸‹å‘½ä»¤æ¥åˆ é™¤ä½è´¨é‡ episodeï¼š\n")
    
    task_dir = os.path.dirname(results[0]['ep_path'])
    
    cmd = f"python python/data_collection/clean_bad_episodes.py \\\n"
    cmd += f"    --task_dir {task_dir} \\\n"
    cmd += f"    --bad_episodes {' '.join(unusable)}"
    
    print(cmd)
    print("\n" + "=" * 80)
    
    return cmd


def main():
    parser = argparse.ArgumentParser(description="é«˜çº§æ•°æ®è´¨é‡è¯Šæ–­")
    parser.add_argument("--task_dir", type=str, required=True, help="ä»»åŠ¡ç›®å½•")
    parser.add_argument("--dt", type=float, default=0.01, help="æ§åˆ¶æ—¶é—´æ­¥ï¼ˆç§’ï¼‰")
    parser.add_argument("--min_score", type=int, default=60, help="æœ€ä½å¯ç”¨åˆ†æ•°")
    parser.add_argument("--no_report", action="store_true", help="ä¸ä¿å­˜æŠ¥å‘Š")
    args = parser.parse_args()
    
    results = diagnose_dataset(
        args.task_dir,
        dt=args.dt,
        min_score=args.min_score,
        save_report=not args.no_report
    )
    
    if results:
        generate_clean_command(results, min_score=args.min_score)


if __name__ == "__main__":
    main()

